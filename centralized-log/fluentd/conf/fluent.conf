<source>
  @type kafka_group
  
  # SSL
  ssl_ca_cert "#{ENV['KAFKA_SSL_CA']}"
  ssl_client_cert "#{ENV['KAFKA_SSL_CLIENT_CRT']}"
  ssl_client_cert_key "#{ENV['KAFKA_SSL_CLIENT_KEY']}"

  # SASL (PLAIN)
  username "#{ENV['KAFKA_PLAIN_USER']}"
  password "#{ENV['KAFKA_PLAIN_PASSWORD']}"

  brokers centralized-log-kafka1:9562,centralized-log-kafka2:9562,centralized-log-kafka3:9562
  consumer_group fluentd
  topics topic_log

</source>

<match topic_log>
  @type copy

  <store>
    @type elasticsearch
    
    hosts centralized-log-elasticsearch1:9200,centralized-log-elasticsearch2:9200,centralized-log-elasticsearch3:9200,centralized-log-elasticsearch4:9200
    scheme https

    # Basic Auth
    user "#{ENV['ELASTIC_USER']}"
    password "#{ENV['ELASTIC_PASSWORD']}"
    
    # mTLS
    ca_file "#{ENV['ELASTIC_SSL_CA']}"
    client_cert "#{ENV['ELASTIC_SSL_CLIENT_CRT']}"
    client_key "#{ENV['ELASTIC_SSL_CLIENT_KEY']}"

    # index example super-group-apps.test-log-nginx-2023.05.03
    logstash_format true
    logstash_prefix ${app}.${app_part}

    # собирает chunk по app и app_part, потом через 1 сек пытается отправить в elastic
    <buffer app, app_part>
      flush_interval 1s
    </buffer>
  </store>

  <store>
    @type stdout
  </store>

</match>